# Google Colab Guide

## ðŸš€ Quick Start

### Cell 1: Setup
```python
# Clone repository
!git clone https://github.com/your-username/Finetune-PhoBERT.git

# QUAN TRá»ŒNG: CD vÃ o project (dÃ¹ng % khÃ´ng pháº£i !)
%cd /content/Finetune-PhoBERT

# Install dependencies
!pip install -q -r requirements.txt
```

### Cell 2: Check Data
```python
import pandas as pd

train_df = pd.read_csv('data/train.csv')
valid_df = pd.read_csv('data/valid.csv')
test_df = pd.read_csv('data/test.csv')

print(f"Train: {len(train_df)} samples")
print(f"Valid: {len(valid_df)} samples")
print(f"Test: {len(test_df)} samples")
print(f"\nLabel distribution:\n{train_df['label'].value_counts()}")
```

### Cell 3: Train Model
```python
# Train (takes ~15-30 mins with GPU)
!python src/train.py
```

### Cell 4: Visualize Training
```python
# Generate training curves
!python src/plot_training.py

# Display
from IPython.display import Image, display
display(Image('out/metrics/training_curves.png'))
```

### Cell 5: Evaluate
```python
# Run evaluation (generates all plots)
!python src/evaluation.py
```

### Cell 6: View Results
```python
from IPython.display import Image, display

# Confusion Matrix
print("Confusion Matrix (Normalized):")
display(Image('out/metrics/confusion_matrix_norm.png'))

# ROC Curve
print("\nROC Curve:")
display(Image('out/metrics/roc_curve.png'))

# PR Curve (important for imbalanced data!)
print("\nPrecision-Recall Curve:")
display(Image('out/metrics/pr_curve.png'))

# Threshold Analysis
print("\nThreshold Analysis:")
display(Image('out/metrics/threshold_analysis.png'))

# Prediction Distribution
print("\nPrediction Distribution:")
display(Image('out/metrics/prediction_dist.png'))
```

### Cell 7: View Report
```python
# Training report
!cat out/metrics/training_report.md

# Metrics JSON
import json
with open('out/metrics/report.json', 'r') as f:
    print(json.dumps(json.load(f), indent=2))
```

### Cell 8: Download Results
```python
# Zip all results
!zip -r results.zip out/metrics/ models/phobert-moderation/

# Download
from google.colab import files
files.download('results.zip')
```

---

## âš ï¸ Common Issues

### Issue 1: `TypeError: evaluation_strategy` 
**Fixed!** Code Ä‘Ã£ update cho transformers má»›i.

### Issue 2: `FileNotFoundError: data/`
**Solution**: Cháº¯c cháº¯n Ä‘Ã£ cháº¡y `%cd /content/Finetune-PhoBERT` trÆ°á»›c!

### Issue 3: CUDA out of memory
**Solutions**:
- Giáº£m `BATCH_TRAIN` trong `src/train.py` (line 27)
- Giáº£m `MAX_LENGTH` (line 26)
- DÃ¹ng Runtime > Change runtime type > T4 GPU

### Issue 4: Session timeout
**Solution**: 
- Download model thÆ°á»ng xuyÃªn
- Hoáº·c mount Google Drive:
```python
from google.colab import drive
drive.mount('/content/drive')
# Sau Ä‘Ã³ copy káº¿t quáº£ vÃ o Drive
!cp -r out/ /content/drive/MyDrive/phobert-results/
```

---

## ðŸŽ¯ Tips

1. **Enable GPU**: Runtime > Change runtime type > GPU (T4)
2. **Monitor training**: Training logs hiá»ƒn thá»‹ realtime
3. **Save checkpoints**: Model tá»± Ä‘á»™ng lÆ°u best checkpoint
4. **Download early**: Download results ngay sau train Ä‘á»ƒ trÃ¡nh máº¥t data

---

## ðŸ“Š Expected Output Structure

```
/content/Finetune-PhoBERT/
â”œâ”€â”€ out/metrics/
â”‚   â”œâ”€â”€ training_report.json
â”‚   â”œâ”€â”€ training_report.md
â”‚   â”œâ”€â”€ train_log.ndjson
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ confusion_matrix_norm.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ pr_curve.png
â”‚   â”œâ”€â”€ threshold_analysis.png
â”‚   â”œâ”€â”€ prediction_dist.png
â”‚   â””â”€â”€ report.json
â””â”€â”€ models/phobert-moderation/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ pytorch_model.bin
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ ...
```

All files ready for your research report! ðŸŽ‰

